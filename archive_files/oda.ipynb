{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4865406a-cc4d-4cc6-b8ca-96ea5359a9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340fd966-1954-4dbd-bd7a-9bcd33469eb7",
   "metadata": {},
   "source": [
    "## GBR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce72fb1a-77f3-4644-90fa-555bf6f9bca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_param_grid = {\n",
    "    'n_estimators': [50, 100, 150],  \n",
    "    'max_depth': [3, 4, 5, 6],     \n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    #'subsample': [0.5, 0.7, 0.9, 1.0],\n",
    "    #'min_samples_split': [2, 5, 10],\n",
    "    #'min_samples_leaf': [1, 2, 4],\n",
    "    #'max_features': ['auto', 'sqrt', 'log2', 0.5, 0.7, None],\n",
    "    #'min_impurity_decrease': [0.0, 0.01, 0.05]\n",
    "}\n",
    "\n",
    "def create_and_tune_gbr(X_train, y_train, X_val, y_val):\n",
    "    # Combine training and validation data\n",
    "    X_combined = np.vstack((X_train, X_val))\n",
    "    y_combined = np.hstack((y_train, y_val))\n",
    "    print(\"hello\")\n",
    "    # Create a predefined split for GridSearchCV\n",
    "    test_fold = [-1]*len(X_train) + [0]*len(X_val)\n",
    "    ps = PredefinedSplit(test_fold)\n",
    "    \n",
    "    # Initialize GridSearchCV\n",
    "    gridsearch = GridSearchCV(GradientBoostingRegressor(random_state=1), \n",
    "                              gbr_param_grid, \n",
    "                              cv=ps, \n",
    "                              scoring='neg_mean_squared_error', \n",
    "                              n_jobs=-1)\n",
    "\n",
    "    # Fit the model\n",
    "    gridsearch.fit(X_combined, y_combined)\n",
    "    \n",
    "    \n",
    "    return gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251eab4a-4cb3-42b4-a936-122f533fe3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_A_gbr[y_pred_a_gbr < 0] = 0\n",
    "y_pred_B_gbr[y_pred_b_gbr < 0] = 0\n",
    "y_pred_C_gbr[y_pred_c_gbr < 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4650ad-f68b-44f5-ba9a-485f8a74ee13",
   "metadata": {},
   "source": [
    "## Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2b525f-6d84-46ae-bf1b-001c6e2eadde",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_param_grid = {\n",
    "    'iterations': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'depth': [4, 6, 8],\n",
    "    # Add other hyperparameters you want to tune\n",
    "}\n",
    "\n",
    "def create_and_tune_catboost(X_train, y_train, X_val, y_val):\n",
    "    # Combine training and validation data\n",
    "    X_combined = np.vstack((X_train, X_val))\n",
    "    y_combined = np.hstack((y_train, y_val))\n",
    "    \n",
    "    # Create a predefined split for GridSearchCV\n",
    "    test_fold = [-1]*len(X_train) + [0]*len(X_val)\n",
    "    ps = PredefinedSplit(test_fold)\n",
    "    \n",
    "    # Initialize GridSearchCV with CatBoostRegressor\n",
    "    gridsearch = GridSearchCV(CatBoostRegressor(), \n",
    "                              cat_param_grid, \n",
    "                              cv=ps, \n",
    "                              scoring='neg_mean_squared_error', \n",
    "                              n_jobs=-1)\n",
    "\n",
    "    # Fit the model\n",
    "    gridsearch.fit(X_combined, y_combined)\n",
    "    \n",
    "    # Make predictions on the validation set using the best model\n",
    "    y_pred = gridsearch.best_estimator_.predict(X_val)\n",
    "    \n",
    "    return gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1cab6d-1244-43d8-a6f8-d7a3cf322f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_model_A = create_and_tune_catboost(X_train_A, y_train_A, X_val_A, y_val_A)\n",
    "catboost_model_B = create_and_tune_catboost(X_train_B, y_train_B, X_val_B, y_val_B)\n",
    "catboost_model_C = create_and_tune_catboost(X_train_C, y_train_C, X_val_C, y_val_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a4f98e-9df4-492e-a2ca-bef17a00a9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_a_catboost = catboost_model_A.predict(X_test_A).ravel()\n",
    "y_pred_b_catboost = catboost_model_B.predict(X_test_B).ravel()\n",
    "y_pred_c_catboost = catboost_model_C.predict(X_test_C).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dbdb69-a8bd-4323-bd52-6df3ad2d9bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_a_catboost[y_pred_a_lgbm < 0] = 0\n",
    "y_pred_b_catboost[y_pred_b_lgbm < 0] = 0\n",
    "y_pred_c_catboost[y_pred_c_lgbm < 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6177c92-bf6c-4df7-b1e0-f92f3f58e881",
   "metadata": {},
   "source": [
    "## Scaling values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99072385-2f2a-4b94-ae4f-5fcf41fb2c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_values(values, orig_min, orig_max, scaled_min, scaled_max):\n",
    "    return [(x - orig_min) / (orig_max - orig_min) * (scaled_max - scaled_min) + scaled_min for x in values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1da8c9-5370-46a0-b8e6-9e4da2c95085",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_A_mlp = scale_values(y_pred_a_mlp, min(y_pred_a_mlp), max(y_pred_a_mlp),0, 5000)\n",
    "y_pred_B_mlp = scale_values(y_pred_b_mlp, min(y_pred_b_mlp), max(y_pred_b_mlp), 0, 1000)\n",
    "y_pred_C_mlp = scale_values(y_pred_c_mlp, min(y_pred_c_mlp), max(y_pred_c_mlp), 0, 1000)\n",
    "\n",
    "y_pred_A_lgbm = scale_values(y_pred_a_lgbm, min(y_pred_a_lgbm), max(y_pred_a_lgbm),0, 5000)\n",
    "y_pred_B_lgbm = scale_values(y_pred_b_lgbm, min(y_pred_b_lgbm), max(y_pred_b_lgbm), 0, 1000)\n",
    "y_pred_C_lgbm = scale_values(y_pred_c_lgbm, min(y_pred_c_lgbm), max(y_pred_c_lgbm), 0, 1000)\n",
    "\n",
    "y_pred_A_gbr = scale_values(y_pred_a_gbr, min(y_pred_a_gbr), max(y_pred_a_gbr),0, 5000)\n",
    "y_pred_B_gbr = scale_values(y_pred_b_gbr, min(y_pred_b_gbr), max(y_pred_b_gbr), 0, 1000)\n",
    "y_pred_C_gbr = scale_values(y_pred_c_gbr, min(y_pred_c_gbr), max(y_pred_c_gbr), 0, 1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66752755-7c4d-46c9-94b9-205e42b65a0e",
   "metadata": {},
   "source": [
    "## LGBM several models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10519c11-53c6-4f97-a1d8-7f99102c3ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lgbm_models(X_train, y_train, X_val, y_val, lgbm_param_grid_1, lgbm_param_grid_2):\n",
    "    model_1 = lgb.LGBMRegressor(**lgbm_param_grid_1, verbose=-1)\n",
    "    model_1.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=100)\n",
    "\n",
    "    model_2 = lgb.LGBMRegressor(**lgbm_param_grid_2, verbose=-1)\n",
    "    model_2.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=100)\n",
    "\n",
    "    return model_1, model_2\n",
    "\n",
    "lgbm_param_grid_1 = {\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 400,\n",
    "    'random_state': 1,\n",
    "    'max_depth': 8,\n",
    "    'subsample': 0.5,\n",
    "    'boosting_type': 'gbdt'\n",
    "}\n",
    "\n",
    "lgbm_param_grid_2 = {\n",
    "    'learning_rate': 0.01,\n",
    "    'n_estimators': 150,\n",
    "    'random_state': 1,\n",
    "    'max_depth': 3,\n",
    "    'subsample': 0.8,\n",
    "    'boosting_type': 'goss'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa39441f-b0a5-4bf7-ac16-0198ae832fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_model_A2, lgbm_model_A3 = create_lgbm_models(X_train_A, y_train_A, X_val_A, y_val_A, lgbm_param_grid_1, lgbm_param_grid_2)\n",
    "lgbm_model_B2, lgbm_model_B3 = create_lgbm_models(X_train_B, y_train_B, X_val_B, y_val_B, lgbm_param_grid_1, lgbm_param_grid_2)\n",
    "lgbm_model_C2, lgbm_model_C3 = create_lgbm_models(X_train_C, y_train_C, X_val_C, y_val_C, lgbm_param_grid_1, lgbm_param_grid_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c3910e-611d-479b-8e9b-42deb4e0ebb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_a_lgbm2 = lgbm_model_A2.predict(X_test_A).ravel()\n",
    "y_pred_b_lgbm2 = lgbm_model_B2.predict(X_test_B).ravel()\n",
    "y_pred_c_lgbm2 = lgbm_model_C2.predict(X_test_C).ravel()\n",
    "\n",
    "y_pred_a_lgbm3 = lgbm_model_A3.predict(X_test_A).ravel()\n",
    "y_pred_b_lgbm3 = lgbm_model_B3.predict(X_test_B).ravel()\n",
    "y_pred_c_lgbm3 = lgbm_model_C3.predict(X_test_C).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec89f790-3794-409d-852c-78b29aa9db71",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_a_lgbm[y_pred_a_lgbm2 < 0] = 0\n",
    "y_pred_b_lgbm[y_pred_b_lgbm2 < 0] = 0\n",
    "y_pred_c_lgbm[y_pred_c_lgbm2 < 0] = 0\n",
    "\n",
    "y_pred_a_lgbm[y_pred_a_lgbm3 < 0] = 0\n",
    "y_pred_b_lgbm[y_pred_b_lgbm3 < 0] = 0\n",
    "y_pred_c_lgbm[y_pred_c_lgbm3 < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42b714c-59ab-42d7-adea-490cf278cf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_A = np.power(np.maximum(y_pred_a_lgbm * y_pred_a_mlp * y_pred_a_lgbm2 * y_pred_a_lgbm3, 0), 1/4)\n",
    "y_pred_B = np.power(np.maximum(y_pred_b_lgbm * y_pred_b_mlp * y_pred_b_lgbm2 * y_pred_b_lgbm3, 0), 1/4)\n",
    "y_pred_C = np.power(np.maximum(y_pred_c_lgbm * y_pred_c_mlp * y_pred_c_lgbm2 * y_pred_c_lgbm3, 0), 1/4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d196cc-58f3-46c6-8ffb-4f58eb070f32",
   "metadata": {},
   "source": [
    "## HIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5aef3c-d3f3-4791-8747-5d861de8e581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid\n",
    "hist_param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.5],\n",
    "    'max_iter': [50, 100],\n",
    "    'max_leaf_nodes': [31, None],\n",
    "    'l2_regularization': [0.0, 0.1],\n",
    "    'max_depth': [None, 10],\n",
    "    'min_samples_leaf': [1, 20],\n",
    "    'loss': ['squared_error', 'poisson'],\n",
    "   'early_stopping': [False, True],\n",
    "    'n_iter_no_change': [10],  # if early_stopping is True\n",
    "    'tol': [1e-6]\n",
    "    'learning_rate': [0.1],\n",
    "    'max_iter': [50],\n",
    "    'loss': ['squared_error']\n",
    "}\n",
    "\n",
    "def create_and_tune_histgb(X_train, y_train, X_val, y_val):\n",
    "    X_combined = np.vstack((X_train, X_val))\n",
    "    y_combined = np.hstack((y_train, y_val))\n",
    "\n",
    "    test_fold = [-1]*len(X_train) + [0]*len(X_val)\n",
    "    \n",
    "    ps = PredefinedSplit(test_fold)\n",
    "\n",
    "    gridsearch = GridSearchCV(HistGradientBoostingRegressor(), hist_param_grid, cv=ps, scoring='neg_mean_absolute_error', verbose=1)\n",
    "\n",
    "    gridsearch.fit(X_combined, y_combined)\n",
    "\n",
    "    print(\"Best Mean Absolute Error from Grid Search:\", -gridsearch.best_score_)\n",
    "\n",
    "    return gridsearch.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da6369b-2530-4820-ba8d-27d2f05b019d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_model_A = create_and_tune_histgb(X_train_A, y_train_A, X_val_A, y_val_A)\n",
    "hist_model_B = create_and_tune_histgb(X_train_B, y_train_B, X_val_B, y_val_B)\n",
    "hist_model_C = create_and_tune_histgb(X_train_C, y_train_C, X_val_C, y_val_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e80d824-5483-464c-9c82-51e307beaa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_a_hist = hist_model_A.predict(X_test_A).ravel()\n",
    "y_pred_b_hist = hist_model_B.predict(X_test_B).ravel()\n",
    "y_pred_c_hist = hist_model_C.predict(X_test_C).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0639685e-1c07-4f93-a484-73079a33cccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_a_hist[y_pred_a_hist < 0] = 0\n",
    "y_pred_b_hist[y_pred_b_hist < 0] = 0\n",
    "y_pred_c_hist[y_pred_c_hist < 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3415a6-a1cc-4e90-a4e7-d0e8597de716",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdddd1c-b2c9-4f92-b61c-7f4200e9c64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model_A = train_and_save_mlp_model(X_train_A, y_train_A, X_val_A, y_val_A, 'models/model_location_A.h5')\n",
    "mlp_model_B = train_and_save_mlp_model(X_train_B, y_train_B, X_val_B, y_val_B, 'models/model_location_B.h5')\n",
    "mlp_model_C = train_and_save_mlp_model(X_train_C, y_train_C, X_val_C, y_val_C, 'models/model_location_C.h5')\n",
    "\n",
    "lgbm_model_A = create_and_tune_lgbm(X_train_A, y_train_A, X_val_A, y_val_A)\n",
    "lgbm_model_B = create_and_tune_lgbm(X_train_B, y_train_B, X_val_B, y_val_B)\n",
    "lgbm_model_C = create_and_tune_lgbm(X_train_C, y_train_C, X_val_C, y_val_C)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-11:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
