{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory: .\n",
      "  File: modelling_oneLoc.ipynb\n",
      "  File: my_first_submission.csv\n",
      "  File: .DS_Store\n",
      "  File: explore_locA.ipynb\n",
      "  File: test.csv\n",
      "  File: Readme.md\n",
      "  File: modelling_allLoc.ipynb\n",
      "  File: sample_submission.csv\n",
      "  File: read_files.ipynb\n",
      "Directory: ./A\n",
      "  File: X_train_observed.parquet\n",
      "  File: train_targets.parquet\n",
      "  File: X_train_estimated.parquet\n",
      "  File: X_test_estimated.parquet\n",
      "Directory: ./C\n",
      "  File: X_train_observed.parquet\n",
      "  File: train_targets.parquet\n",
      "  File: X_train_estimated.parquet\n",
      "  File: X_test_estimated.parquet\n",
      "Directory: ./B\n",
      "  File: X_train_observed.parquet\n",
      "  File: train_targets.parquet\n",
      "  File: X_train_estimated.parquet\n",
      "  File: X_test_estimated.parquet\n"
     ]
    }
   ],
   "source": [
    "def list_directory_tree_with_os_walk(starting_directory):\n",
    "    for root, directories, files in os.walk(starting_directory):\n",
    "        print(f\"Directory: {root}\")\n",
    "        for file in files:\n",
    "            print(f\"  File: {file}\")\n",
    "\n",
    "list_directory_tree_with_os_walk('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_a = pd.read_parquet('A/train_targets.parquet')\n",
    "train_b = pd.read_parquet('B/train_targets.parquet')\n",
    "train_c = pd.read_parquet('C/train_targets.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_estimated_a = pd.read_parquet('A/X_train_estimated.parquet')\n",
    "X_train_estimated_b = pd.read_parquet('B/X_train_estimated.parquet')\n",
    "X_train_estimated_c = pd.read_parquet('C/X_train_estimated.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_observed_a = pd.read_parquet('A/X_train_observed.parquet')\n",
    "X_train_observed_b = pd.read_parquet('B/X_train_observed.parquet')\n",
    "X_train_observed_c = pd.read_parquet('C/X_train_observed.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_estimated_a = pd.read_parquet('A/X_test_estimated.parquet')\n",
    "X_test_estimated_b = pd.read_parquet('B/X_test_estimated.parquet')\n",
    "X_test_estimated_c = pd.read_parquet('C/X_test_estimated.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_estimated_a['hourly_timestamp'] = X_train_estimated_a['date_forecast'].dt.floor('H')\n",
    "# Group by 'hourly_timestamp' and calculate the mean for each group\n",
    "X_train_estimated_a = X_train_estimated_a.groupby('hourly_timestamp').mean().reset_index()\n",
    "# Drop the 'hourly_timestamp' column if you don't need it in the final DataFrame\n",
    "X_train_estimated_a.drop(columns=['hourly_timestamp'], inplace=True)\n",
    "X_train_estimated_a['date_forecast'] = X_train_estimated_a['date_forecast'].dt.floor('H')\n",
    "\n",
    "X_train_observed_a['hourly_timestamp'] = X_train_observed_a['date_forecast'].dt.floor('H')\n",
    "# Group by 'hourly_timestamp' and calculate the mean for each group\n",
    "X_train_observed_a = X_train_observed_a.groupby('hourly_timestamp').mean().reset_index()\n",
    "# Drop the 'hourly_timestamp' column if you don't need it in the final DataFrame\n",
    "X_train_observed_a.drop(columns=['hourly_timestamp'], inplace=True)\n",
    "X_train_observed_a['date_forecast'] = X_train_observed_a['date_forecast'].dt.floor('H')\n",
    "\n",
    "X_test_estimated_a['hourly_timestamp'] = X_test_estimated_a['date_forecast'].dt.floor('H')\n",
    "# Group by 'hourly_timestamp' and calculate the mean for each group\n",
    "X_test_estimated_a = X_test_estimated_a.groupby('hourly_timestamp').mean().reset_index()\n",
    "# Drop the 'hourly_timestamp' column if you don't need it in the final DataFrame\n",
    "X_test_estimated_a.drop(columns=['hourly_timestamp'], inplace=True)\n",
    "X_test_estimated_a['date_forecast'] = X_test_estimated_a['date_forecast'].dt.floor('H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_a.rename(columns={'time': 'date_forecast'}, inplace=True)\n",
    "\n",
    "validation = X_train_estimated_a.merge(train_a[['date_forecast', 'pv_measurement']], \n",
    "                        how='left', \n",
    "                        on=['date_forecast'], \n",
    "                        suffixes=('', '_target'))\n",
    "\n",
    "# Fill NaN values in 'pv_measurement' column with 0 if needed\n",
    "#training['pv_measurement'].fillna(0, inplace=True)\n",
    "validation = validation.dropna(subset=['pv_measurement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_a.rename(columns={'time': 'date_forecast'}, inplace=True)\n",
    "\n",
    "training = X_train_observed_a.merge(train_a[['date_forecast', 'pv_measurement']], \n",
    "                        how='left', \n",
    "                        on=['date_forecast'], \n",
    "                        suffixes=('', '_target'))\n",
    "\n",
    "# Fill NaN values in 'pv_measurement' column with 0 if needed\n",
    "#training['pv_measurement'].fillna(0, inplace=True)\n",
    "training = training.dropna(subset=['pv_measurement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Split your data into features (X) and the target variable (y)\n",
    "X_train = training.drop(columns=['pv_measurement'])  # Exclude the target column\n",
    "X_train = X_train.drop(columns=['date_forecast'])\n",
    "X_train.fillna(0, inplace=True)  # Fill NaN values with 0 in X_train\n",
    "y_train = training['pv_measurement']\n",
    "\n",
    "X_val = validation.drop(columns=['pv_measurement'])  # Exclude the target column\n",
    "X_val = X_val.drop(columns=['date_forecast'])\n",
    "X_val = X_val.drop(columns=['date_calc'])\n",
    "X_val.fillna(0, inplace=True)  # Fill NaN values with 0 in X_val\n",
    "y_val = validation['pv_measurement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on validation data: 123092.49\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Step 2: Create and train the Random Forest model\n",
    "rf_model = RandomForestRegressor(n_estimators=10, random_state=10)  # You can adjust hyperparameters\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Evaluate the model's performance on the validation data\n",
    "y_pred = rf_model.predict(X_val)\n",
    "\n",
    "# Calculate the mean squared error (MSE)\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "print(f'Mean Squared Error on validation data: {mse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 141436.63295475199\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model.predict(X_val)\n",
    "\n",
    "# Evaluate the model (e.g., using mean squared error)\n",
    "mse = mean_squared_error(y_val, predictions)\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
